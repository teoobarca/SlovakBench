# Models to evaluate
# Add/remove models as needed

MODELS = [
    #openai
    "openai/gpt-3.5-turbo",
    "openai/gpt-4-turbo",
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "openai/gpt-4.1-nano",
    "openai/gpt-4.1-mini",
    "openai/gpt-4.1",
    "openai/o4-mini-high",
    "openai/o3",
    "openai/gpt-5-nano",
    "openai/gpt-5-mini",
    "openai/gpt-5",
    "openai/gpt-5.1",
    "openai/gpt-5.1-chat",
    "openai/gpt-5.2",
    "openai/gpt-5.2-chat",


    #anthropic
    "anthropic/claude-3-haiku",
    # "anthropic/claude-3-sonnet",
    # "anthropic/claude-3-opus",
    "anthropic/claude-3.5-sonnet",
    "anthropic/claude-3.5-haiku",
    # "anthropic/claude-3.5-opus",
    # "anthropic/claude-3.5-haiku-20241022",
    "anthropic/claude-3.7-sonnet:thinking",
    "anthropic/claude-sonnet-4",
    # "anthropic/claude-opus-4",
    # "anthropic/claude-opus-4.1",
    "anthropic/claude-haiku-4.5",
    "anthropic/claude-sonnet-4.5",
    "anthropic/claude-opus-4.5",


    #google
    "google/gemini-2.0-flash-001",
    # "google/gemini-2.0-flash-exp:free",
    "google/gemini-2.5-flash",
    "google/gemini-2.5-flash-preview-09-2025",
    "google/gemini-2.5-flash-lite",
    "google/gemini-2.5-flash-lite-preview-09-2025",
    "google/gemini-2.5-pro",
    "google/gemini-3-pro-preview",

    #mistral
    "mistralai/devstral-2512",
    "mistralai/ministral-14b-2512",
    "mistralai/mistral-large-2512",
    "mistralai/mistral-saba",
    "mistralai/mistral-medium-3",
    "mistralai/mistral-medium-3.1",
    "mistral/ministral-8b",
    "mistralai/mistral-small-3.2-24b-instruct",
    "mistralai/devstral-small",
    "mistralai/devstral-medium",
    "mistralai/codestral-2508",
    

    #moonshot
    "moonshotai/kimi-k2-thinking",
    "moonshotai/kimi-k2-0905",
    "moonshotai/kimi-k2",

    #minimax
    # "minimax/minimax-01",
    "minimax/minimax-m1",
    "minimax/minimax-m2",
    

    #qwen
    "qwen/qwen3-vl-8b-thinking",
    "qwen/qwen3-vl-8b-instruct",
    "qwen/qwen3-vl-30b-a3b-thinking",
    "qwen/qwen3-vl-30b-a3b-instruct",
    "qwen/qwen3-vl-235b-a22b-thinking",
    "qwen/qwen3-vl-235b-a22b-instruct",
    "qwen/qwen3-max",
    "qwen/qwen3-coder-plus",
    "qwen/qwen3-coder-flash",
    "qwen/qwen3-next-80b-a3b-thinking",
    "qwen/qwen3-next-80b-a3b-instruct",
    "qwen/qwen-plus-2025-07-28:thinking",
    "qwen/qwen3-30b-a3b-thinking-2507",
    "qwen/qwen3-coder-30b-a3b-instruct",
    "qwen/qwen3-30b-a3b-instruct-2507",
    "qwen/qwen3-235b-a22b-thinking-2507",
    "qwen/qwen3-coder",
    "qwen/qwen3-235b-a22b-2507",
    "qwen/qwen3-30b-a3b",
    "qwen/qwen3-8b",
    "qwen/qwen3-32b",

    #zai
    "z-ai/glm-4-32b",
    "z-ai/glm-4.5-air",
    "z-ai/glm-4.5",
    "z-ai/glm-4.5v",
    "z-ai/glm-4.6",
    "z-ai/glm-4.6v",

    #meta
    "meta-llama/llama-3-8b-instruct",
    "meta-llama/llama-3-70b-instruct",
    "meta-llama/llama-3.1-70b-instruct",
    "meta-llama/llama-3.1-405b-instruct",
    "meta-llama/llama-3.1-8b-instruct",
    "meta-llama/llama-3.2-1b-instruct",
    "meta-llama/llama-3.2-3b-instruct",
    "meta-llama/llama-3.3-70b-instruct",
    "meta-llama/llama-4-scout",
    "meta-llama/llama-4-maverick",
    "meta-llama/llama-guard-4-12b",


    #xai
    "x-ai/grok-3",
    "x-ai/grok-3-mini",
    "x-ai/grok-4",
    "x-ai/grok-code-fast-1",
    "x-ai/grok-4-fast",
    "x-ai/grok-4.1-fast",

    #cohere
    "cohere/command-r-plus-08-2024",
    "cohere/command-r-08-2024",
    "cohere/command-r7b-12-2024",
    "cohere/command-a",

    #a21
    "ai21/jamba-large-1.7",
    "ai21/jamba-mini-1.7",

    #microsoft
    "microsoft/phi-3-mini-128k-instruct",
    "microsoft/phi-3.5-mini-128k-instruct",
    "microsoft/phi-4",
    "microsoft/phi-4-multimodal-instruct",
    "microsoft/phi-4-reasoning-plus",
]
